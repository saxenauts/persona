# Environment Variables
# Copy this to .env and fill in your API keys

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Format: provider/model
# Providers: openai, foundry, azure, anthropic, gemini

LLM_SERVICE=openai/gpt-5.2
EMBEDDING_SERVICE=openai/text-embedding-3-small

# OpenAI (default for new users)
OPENAI_API_KEY=

# Azure AI Foundry (alternative - for enterprise/production)
# LLM_SERVICE=foundry/gpt-5.2
# AZURE_API_KEY=
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_CHAT_DEPLOYMENT=gpt-5.2
# AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# =============================================================================
# Neo4j Database
# =============================================================================
# IMPORTANT: Use the correct URI based on your environment:
#
# Running inside Docker (docker compose up):
#   URI_NEO4J=bolt://neo4j:7687
#
# Running locally (poetry run python ...):
#   URI_NEO4J=bolt://localhost:7687
#
URI_NEO4J=bolt://neo4j:7687
USER_NEO4J=neo4j
PASSWORD_NEO4J=password
NEO4J_AUTH=neo4j/password

# =============================================================================
# Performance Tuning
# =============================================================================
# Parallel session ingestion (for multi-session batch ingestion)
INGEST_SESSION_CONCURRENCY=5

# Eval judge model (for evals only)
EVAL_JUDGE_MODEL=gpt-5-mini

